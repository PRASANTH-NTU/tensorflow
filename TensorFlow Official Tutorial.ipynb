{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    " # Table of Contents\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\" id=\"toc-level0\"><li><span><a href=\"http://localhost:8888/notebooks/Dropbox/Python%20Folder/tensorflows%20official/TensorFlow%20Official%20Tutorial.ipynb#TenorFlow\" data-toc-modified-id=\"TenorFlow-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>TenorFlow</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8888/notebooks/Dropbox/Python%20Folder/tensorflows%20official/TensorFlow%20Official%20Tutorial.ipynb#Tensors\" data-toc-modified-id=\"Tensors-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Tensors</a></span></li></ul></li><li><span><a href=\"http://localhost:8888/notebooks/Dropbox/Python%20Folder/tensorflows%20official/TensorFlow%20Official%20Tutorial.ipynb#TensorFlow-Core-Tutorial\" data-toc-modified-id=\"TensorFlow-Core-Tutorial-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>TensorFlow Core Tutorial</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8888/notebooks/Dropbox/Python%20Folder/tensorflows%20official/TensorFlow%20Official%20Tutorial.ipynb#Computational-Graph\" data-toc-modified-id=\"Computational-Graph-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Computational Graph</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8888/notebooks/Dropbox/Python%20Folder/tensorflows%20official/TensorFlow%20Official%20Tutorial.ipynb#Constant\" data-toc-modified-id=\"Constant-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Constant</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/Dropbox/Python%20Folder/tensorflows%20official/TensorFlow%20Official%20Tutorial.ipynb#Placeholder\" data-toc-modified-id=\"Placeholder-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Placeholder</a></span></li></ul></li><li><span><a href=\"http://localhost:8888/notebooks/Dropbox/Python%20Folder/tensorflows%20official/TensorFlow%20Official%20Tutorial.ipynb#Linear-Regression-Model\" data-toc-modified-id=\"Linear-Regression-Model-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Linear Regression Model</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8888/notebooks/Dropbox/Python%20Folder/tensorflows%20official/TensorFlow%20Official%20Tutorial.ipynb#Variables\" data-toc-modified-id=\"Variables-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Variables</a></span></li></ul></li></ul></li><li><span><a href=\"http://localhost:8888/notebooks/Dropbox/Python%20Folder/tensorflows%20official/TensorFlow%20Official%20Tutorial.ipynb#tf.train-API\" data-toc-modified-id=\"tf.train-API-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>tf.train API</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8888/notebooks/Dropbox/Python%20Folder/tensorflows%20official/TensorFlow%20Official%20Tutorial.ipynb#Complete-Program\" data-toc-modified-id=\"Complete-Program-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Complete Program</a></span></li></ul></li><li><span><a href=\"http://localhost:8888/notebooks/Dropbox/Python%20Folder/tensorflows%20official/TensorFlow%20Official%20Tutorial.ipynb#tf.estimator\" data-toc-modified-id=\"tf.estimator-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>tf.estimator</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8888/notebooks/Dropbox/Python%20Folder/tensorflows%20official/TensorFlow%20Official%20Tutorial.ipynb#Basic-usage\" data-toc-modified-id=\"Basic-usage-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Basic usage</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/Dropbox/Python%20Folder/tensorflows%20official/TensorFlow%20Official%20Tutorial.ipynb#Custom-model\" data-toc-modified-id=\"Custom-model-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Custom model</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TenorFlow\n",
    "\n",
    "- Provides multiple APIs\n",
    "    - lowest level API - Tensorflow core\n",
    "        - Provides complete programming control\n",
    "        - For machine learning researchers & who require fine control over the models\n",
    "    - higher level API - \n",
    "        - Built on top of Tensorflow core\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "- Central unit of data\n",
    "- Tensor's rank - No of dimensions\n",
    "- Example\n",
    "    - `3` # rank 0 tensor, scalar with shape []\n",
    "    - `[1., 2., 3.]` # a rank 1 tensor; vector with shape [3]\n",
    "    - `[[1., 2., 3.], [4., 5., 6.]]` # a rank 2 tensor; a matrix with shape [2, 3]\n",
    "    - `[[[1., 2., 3.]], [[7., 8., 9.]]]` # a rank 3 tensor; matrix shape [2, 1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Core Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Computational Graph\n",
    "\n",
    "- TensorFlow Core program -> 2 sections\n",
    "    1. Building the computational graph\n",
    "    2. Running the computational graph\n",
    "    <br><br>\n",
    "- **Computational Graph**\n",
    "    - A computational graph is a series of TensorFlow operations arranged into a graph of nodes. \n",
    "    - Let's build a simple computational graph. \n",
    "    - Each node takes zero or more tensors as inputs and produces a tensor as an output. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant\n",
    "   One type of node is a constant. Like all TensorFlow constants, it takes no inputs, and it outputs a value it stores internally. We can create two floating point Tensors node1 and node2 as follows:\n",
    "- Constants are initialised when we call `tf.constant` & their value can never change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1: Tensor(\"const_node1:0\", shape=(), dtype=float32) \n",
      "node2: Tensor(\"Const:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "node1 = tf.constant(3.0, dtype = tf.float32, name='const_node1')\n",
    "node2 = tf.constant(4.0)  # dtype = tf.float32 (implicit definition) and name = and name is implicitly defined and incremented\n",
    "print (\"node1:\", node1, \"\\nnode2:\",node2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that **printing the nodes does not output the values 3.0 and 4.0 as you might expect**. Instead, they are nodes that, when evaluated, would produce 3.0 and 4.0, respectively. To actually evaluate the nodes, we must run the computational graph within a session. A session encapsulates the control and state of the TensorFlow runtime.\n",
    "\n",
    "The following code creates a Session object and then invokes its run method to run enough of the computational graph to evaluate node1 and node2. By running the computational graph in a session as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "sess= tf.Session()\n",
    "print (sess.run([node1, node2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add our two constant nodes and produce a new graph as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1: Tensor(\"const_node1:0\", shape=(), dtype=float32) \n",
      "node2: Tensor(\"Const:0\", shape=(), dtype=float32) \n",
      "node3: Tensor(\"Add:0\", shape=(), dtype=float32)\n",
      "\n",
      "sess.run(node3): 7.0\n"
     ]
    }
   ],
   "source": [
    "node3 = tf.add(node1, node2)              # Add 2 constant nodes & produce new graph\n",
    "print (\"node1:\", node1, \"\\nnode2:\", node2, \"\\nnode3:\", node3)\n",
    "\n",
    "print(\"\\nsess.run(node3):\",sess.run(node3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholder\n",
    "\n",
    "A graph can be parameterized to accept external inputs, known as placeholders. A placeholder is a promise to provide a value later.\n",
    "\n",
    " We can evaluate this graph below with multiple inputs by using the feed_dict argument to the run method to feed concrete values to the placeholders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b                       # a + b == tf.add(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session 1: 7.5\n",
      "Session 1: [ 3.  7.]\n"
     ]
    }
   ],
   "source": [
    "print (\"Session 1:\", sess.run(adder_node, {a:3,b:4.5}))\n",
    "print (\"Session 1:\", sess.run(adder_node, {a:[1,3],b:[2,4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session 3: 22.5\n"
     ]
    }
   ],
   "source": [
    "add_and_triple = adder_node * 3\n",
    "print (\"Session 3:\", sess.run(add_and_triple, {a:3, b:4.5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Model\n",
    "\n",
    "<img src=\"tensorflow images/Cost_function.png\" width=\"500\" height=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "- Variables are not initalised when we call `tf.variable`\n",
    "- To initialize all the variables, we have to call a special operation **`tf.global_variables_initializer()`**\n",
    "- To change the variable value, use `tf.assign`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable([.3], dtype = tf.float32)        # W - variable\n",
    "b = tf.Variable([-.3], dtype = tf.float32)       # b - variable\n",
    "x = tf.placeholder(tf.float32)                   # x - placeholder\n",
    "linear_model = W*x + b                           # Created a linear model manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "print (sess.run(linear_model, {x: [1,2,3,4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the model on training data**\n",
    "- **Loss** or **Cost Function**\n",
    "    - aka **Squared Error Function** or **Mean Squared Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 23.66\n"
     ]
    }
   ],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(linear_model - y)    # Square of deltas = (h - y)^2\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "print (\"Loss:\", sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manually reassigning the weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Alternative to the code below\n",
    "#reassign_W = W.assign([-1])\n",
    "#reassign_b = b.assign([1])\n",
    "#session.run([reassign_W,reassign_b])\n",
    "\n",
    "\n",
    "fixW = tf.assign(W, [-1.])                       # Changing variable value\n",
    "fixb = tf.assign(b, [1.])                        # Changing variable value\n",
    "sess.run([fixW, fixb])                           # explicitly run to update the variable\n",
    "print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.train API\n",
    "**Goal: Minimising cost function (loss) using gradient descent optimization algo**\n",
    "- Doing a simple linear regression\n",
    "- Simplest optimizer\n",
    "    - **Gradient descent** \n",
    "        - Modifies the parameters (weights/ each variable in W and b) according to the magnitude of deritvative of loss with respect to that variable/ \n",
    "        - Similar to [theta0, theta1] update studied in Coursera Machine Learning\n",
    "        - Learning rate $\\alpha$ - .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimiser = tf.train.GradientDescentOptimizer(0.01)   \n",
    "train = optimiser.minimize(loss)                          # loss -> is the cost function, J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training the model: W: [-0.9999969] b: [ 0.99999082]\n",
      "Loss: 5.69997e-11\n"
     ]
    }
   ],
   "source": [
    "sess.run(init)                                   # Reset the W,b variable values to incorrect defaults\n",
    "\n",
    "for i in range(1000):\n",
    "    sess.run(train, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})\n",
    "    \n",
    "print (\"After training the model:\", \"W:\", sess.run(W), \"b:\", sess.run(b))\n",
    "print(\"Loss:\", sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Program\n",
    "\n",
    "The complete trainable linear regression model is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, W: [ 0.30000001] and b: [-0.30000001]\n",
      "Predicted output: [ 0.          0.30000001  0.60000002  0.90000004]\n",
      "\n",
      "Training started....\n",
      "Loss [  0] = [4.0181446075]\n",
      "Loss [ 50] = [0.4766549468]\n",
      "Loss [100] = [0.1428797543]\n",
      "Loss [150] = [0.0428289399]\n",
      "Loss [200] = [0.0128382072]\n",
      "Loss [250] = [0.0038483262]\n",
      "Loss [300] = [0.0011535464]\n",
      "Loss [350] = [0.0003457759]\n",
      "Loss [400] = [0.0001036511]\n",
      "Loss [450] = [0.0000310689]\n",
      "Loss [500] = [0.0000093124]\n",
      "Loss [550] = [0.0000027915]\n",
      "Loss [600] = [0.0000008365]\n",
      "Loss [650] = [0.0000002508]\n",
      "Loss [700] = [0.0000000751]\n",
      "Loss [750] = [0.0000000225]\n",
      "Loss [800] = [0.0000000068]\n",
      "Loss [850] = [0.0000000020]\n",
      "Loss [900] = [0.0000000006]\n",
      "Loss [950] = [0.0000000002]\n",
      "Training ended....\n",
      "\n",
      "After training, W: [-0.9999969] and b: [ 0.99999082]\n",
      "Predicted output: [ -6.07967377e-06  -1.00000298e+00  -1.99999988e+00  -2.99999666e+00]\n",
      "Finally, W: [-0.9999969] b: [ 0.99999082] loss: 5.69997e-11\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Model parameters\n",
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "\n",
    "# Model input and output\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W * x + b\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "# loss or cost function\n",
    "loss = tf.reduce_sum(tf.square(linear_model - y)) # sum of the squares\n",
    "# optimizer (gradient descent) with learning rate = 0.01\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# training data (labelled input & output swt)\n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [0, -1, -2, -3]\n",
    "\n",
    "# training loop (1000 iterations)\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init) # reset values to wrong one\n",
    "\n",
    "print ('Before training, W:', sess.run(W), 'and b:', sess.run(b))\n",
    "print ('Predicted output:', sess.run(linear_model,{x:x_train, y:y_train}))\n",
    "\n",
    "print ('\\nTraining started....')\n",
    "for i in range(1000):\n",
    "  sess.run(train, {x: x_train, y: y_train})\n",
    "  if i%50 == 0:\n",
    "    print('Loss [%3d] = [%2.10f]' %(i,sess.run(loss, {x:x_train, y:y_train})))\n",
    "print ('Training ended....')\n",
    "\n",
    "print ('\\nAfter training, W:', sess.run(W), 'and b:', sess.run(b))\n",
    "print ('Predicted output:', sess.run(linear_model,{x:x_train, y:y_train}))\n",
    "\n",
    "# evaluate training accuracy\n",
    "curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x: x_train, y: y_train})\n",
    "print(\"Finally, W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual output: [-1.01, -4.1, -7, 0.0]\n",
      "Predicted output: [ -1.00000298e+00  -3.99999380e+00  -6.99998426e+00  -6.07967377e-06]\n",
      "Loss for test data: 0.0101012\n"
     ]
    }
   ],
   "source": [
    "x_test = [2., 5., 8., 1.]\n",
    "y_test = [-1.01, -4.1, -7, 0.]\n",
    "\n",
    "h_test, loss_test = sess.run([linear_model,loss], feed_dict={x:x_test, y:y_test})\n",
    "print ('Actual output:', y_test)\n",
    "print ('Predicted output:', h_test)\n",
    "print ('Loss for test data:', loss_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# tf.estimator\n",
    "\n",
    "**`tf.estimator`** defines many common predefined models\n",
    "\n",
    "- High level Tensorflow library\n",
    "- Simplifies the mechanics of machine learning, including\n",
    "    - running training loops\n",
    "    - running evaluation loops\n",
    "    - managing datasets\n",
    "    \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic usage\n",
    "\n",
    "For attribute error, https://stackoverflow.com/questions/45817355/attributeerror-module-tensorflow-python-estimator-estimator-lib-has-no-attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Prasanth\\AppData\\Local\\Temp\\tmpwkzcxz4v\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Prasanth\\\\AppData\\\\Local\\\\Temp\\\\tmpwkzcxz4v', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001EB08D4B208>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Prasanth\\AppData\\Local\\Temp\\tmpwkzcxz4v\\model.ckpt.\n",
      "INFO:tensorflow:loss = 6.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 768.697\n",
      "INFO:tensorflow:loss = 0.448568, step = 101 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 822.463\n",
      "INFO:tensorflow:loss = 0.04274, step = 201 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 920.819\n",
      "INFO:tensorflow:loss = 0.0178121, step = 301 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 925.268\n",
      "INFO:tensorflow:loss = 0.00398037, step = 401 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 880.021\n",
      "INFO:tensorflow:loss = 0.000628744, step = 501 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.167\n",
      "INFO:tensorflow:loss = 0.000107269, step = 601 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 900.276\n",
      "INFO:tensorflow:loss = 1.82204e-05, step = 701 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 888.253\n",
      "INFO:tensorflow:loss = 5.58824e-06, step = 801 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 908.446\n",
      "INFO:tensorflow:loss = 1.04576e-06, step = 901 (0.111 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\Prasanth\\AppData\\Local\\Temp\\tmpwkzcxz4v\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3.04338e-07.\n",
      "INFO:tensorflow:Starting evaluation at 2017-12-23-03:29:43\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Prasanth\\AppData\\Local\\Temp\\tmpwkzcxz4v\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-12-23-03:29:44\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 7.22382e-08, global_step = 1000, loss = 2.88953e-07\n",
      "INFO:tensorflow:Starting evaluation at 2017-12-23-03:29:45\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Prasanth\\AppData\\Local\\Temp\\tmpwkzcxz4v\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-12-23-03:29:46\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 0.00255277, global_step = 1000, loss = 0.0102111\n",
      "train metrics: {'average_loss': 7.2238194e-08, 'loss': 2.8895278e-07, 'global_step': 1000}\n",
      "eval metrics: {'average_loss': 0.0025527696, 'loss': 0.010211078, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# NumPy is often used to load, manipulate and preprocess data.\n",
    "import numpy as np\n",
    "\n",
    "# Declare list of features. We only have one numeric feature. There are many\n",
    "# other types of columns that are more complicated and useful.\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[1])]\n",
    "\n",
    "# An estimator is the front end to invoke training (fitting) and evaluation\n",
    "# (inference). There are many predefined types like linear regression,\n",
    "# linear classification, and many neural network classifiers and regressors.\n",
    "# The following code provides an estimator that does linear regression.\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n",
    "\n",
    "# TensorFlow provides many helper methods to read and set up data sets.\n",
    "# Here we use two data sets: one for training and one for evaluation\n",
    "# We have to tell the function how many batches\n",
    "# of data (num_epochs) we want and how big each batch should be.\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "# We can invoke 1000 training steps by invoking the  method and passing the\n",
    "# training data set.\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "\n",
    "# Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Custom model\n",
    "\n",
    "- **`tf.estimator` doesn't lock us into a predefined model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Prasanth\\AppData\\Local\\Temp\\tmp6c35j9t3\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Prasanth\\\\AppData\\\\Local\\\\Temp\\\\tmp6c35j9t3', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Prasanth\\AppData\\Local\\Temp\\tmp6c35j9t3\\model.ckpt.\n",
      "INFO:tensorflow:loss = 10.8243056552, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1082.03\n",
      "INFO:tensorflow:loss = 0.0105629748841, step = 101 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 974.615\n",
      "INFO:tensorflow:loss = 0.00179632693396, step = 201 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 805.281\n",
      "INFO:tensorflow:loss = 0.000422973883502, step = 301 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 829.163\n",
      "INFO:tensorflow:loss = 6.08114157174e-05, step = 401 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 865.953\n",
      "INFO:tensorflow:loss = 2.54801307064e-06, step = 501 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 932.785\n",
      "INFO:tensorflow:loss = 1.81074072279e-07, step = 601 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 1203.02\n",
      "INFO:tensorflow:loss = 6.35252516583e-09, step = 701 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 890.114\n",
      "INFO:tensorflow:loss = 1.06682811469e-09, step = 801 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 779.851\n",
      "INFO:tensorflow:loss = 1.03150573629e-10, step = 901 (0.127 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\Prasanth\\AppData\\Local\\Temp\\tmp6c35j9t3\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6.30453052307e-12.\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-21-03:21:00\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Prasanth\\AppData\\Local\\Temp\\tmp6c35j9t3\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-21-03:21:01\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 7.89113e-12\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-21-03:21:01\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Prasanth\\AppData\\Local\\Temp\\tmp6c35j9t3\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-21-03:21:02\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.0101004\n",
      "train metrics: {'loss': 7.8911261e-12, 'global_step': 1000}\n",
      "eval metrics: {'loss': 0.010100388, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Declare list of features, we only have one real-valued feature\n",
    "def model_fn(features, labels, mode):\n",
    "  # Build a linear model and predict values\n",
    "  W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "  b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "  y = W * features['x'] + b\n",
    "  # Loss sub-graph\n",
    "  loss = tf.reduce_sum(tf.square(y - labels))\n",
    "  # Training sub-graph\n",
    "  global_step = tf.train.get_global_step()\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "  train = tf.group(optimizer.minimize(loss),\n",
    "                   tf.assign_add(global_step, 1))\n",
    "  # EstimatorSpec connects subgraphs we built to the\n",
    "  # appropriate functionality.\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=y,\n",
    "      loss=loss,\n",
    "      train_op=train)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn)\n",
    "# define our data sets\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "# train\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "# Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
